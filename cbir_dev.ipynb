{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        # transforms.Normalize(mean, std),\n",
    "        # lambda x: torch.flip(x, [1]),\n",
    "        # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ]\n",
    ")\n",
    "dataset = torchvision.datasets.ImageFolder(\n",
    "    root=\"./data/caltech101/train\",\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "valset = torchvision.datasets.ImageFolder(\n",
    "    root=\"./data/caltech101/val\",\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(\n",
    "    root=\"./data/caltech101/test\",\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=128, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    valset, batch_size=128, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=128, shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbir import *\n",
    "from cbir.pipeline import *\n",
    "\n",
    "# rgb_histogram = RGBHistogram(n_bin=8, h_type=\"region\")\n",
    "# resnet = ResNetExtractor(model = \"resnet18\", device=\"cuda\")\n",
    "siftbow = SIFTBOWExtractor(mode=\"tfidf\")\n",
    "sift_array_store = NPArrayStore(retrieve=KNNRetrieval(metric=\"manhattan\"))\n",
    "\n",
    "rgb_histogram = RGBHistogram(n_bin=4, h_type=\"region\")\n",
    "color_array_store = NPArrayStore(retrieve=KNNRetrieval(metric=\"cosine\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]/home/edtechai/miniconda3/envs/yolov10/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/edtechai/miniconda3/envs/yolov10/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 11/11 [00:01<00:00,  7.48it/s]\n",
      "Extracting Features: 100%|██████████| 1326/1326 [00:09<00:00, 140.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Kmeans clustering to create BOW\n",
      "Fit IDF for TF-IDF Transformation\n",
      "Complete Fitting SIFT BOW Extractor\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "train_img = []\n",
    "for images, labels in tqdm(valloader):\n",
    "    images = (images.numpy().transpose(0,2,3,1) * 255).astype(np.uint8)\n",
    "    train_img.append(images)\n",
    "    \n",
    "train_img = np.concatenate(train_img)\n",
    "siftbow.fit(train_img, k=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbir_sift = CBIR(siftbow, sift_array_store)\n",
    "cbir_color = CBIR(siftbow, color_array_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]/home/edtechai/miniconda3/envs/yolov10/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/edtechai/miniconda3/envs/yolov10/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 50/50 [01:43<00:00,  2.08s/it]\n"
     ]
    }
   ],
   "source": [
    "for images, labels in tqdm(dataloader):\n",
    "    images = (images.numpy().transpose(0,2,3,1) * 255).astype(np.uint8)\n",
    "    # images = images.numpy()\n",
    "    cbir_sift.indexing(images)\n",
    "    cbir_color.indexing(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbir.entities.search_objects import ImageSearchObject\n",
    "import torch\n",
    "\n",
    "\n",
    "def ensemble_search(\n",
    "    *args: list[ImageSearchObject], weights: list, datalength: int, k: int = 10\n",
    ") -> list[ImageSearchObject]:\n",
    "    assert len(args) == len(weights), \"Arguments and weights must have same length\"\n",
    "    \n",
    "    for arg in args:\n",
    "        assert isinstance(\n",
    "            arg[0], ImageSearchObject\n",
    "        ), \"Arguments must be list of ImageSearchObject\"\n",
    "\n",
    "    scores = torch.zeros(datalength)\n",
    "    for search_list, weight in zip(args, weights):\n",
    "        search_scores = torch.zeros(datalength).float()\n",
    "        index_tensor = torch.tensor([i.index for i in search_list])\n",
    "        value_tensor = torch.tensor([s.score for s in search_list]).float()\n",
    "        search_scores = search_scores.scatter_(0, index_tensor, value_tensor) * weight\n",
    "        \n",
    "        scores += search_scores\n",
    "    \n",
    "    top = scores.topk(k)\n",
    "    \n",
    "    return [ImageSearchObject(index, score) for index, score in zip(top.indices, top.values)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieval:   0%|          | 0/12 [00:00<?, ?it/s]/home/edtechai/miniconda3/envs/yolov10/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/edtechai/miniconda3/envs/yolov10/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "Retrieval: 100%|██████████| 12/12 [02:07<00:00, 10.66s/it]\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "# Retrieval\n",
    "start = time()\n",
    "rs = []\n",
    "ground_truth = []\n",
    "for images, labels in tqdm(testloader, desc=\"Retrieval\"):\n",
    "    images = (images.numpy().transpose(0, 2, 3, 1) * 255).astype(np.uint8)\n",
    "    for image in images:\n",
    "        rs.append(\n",
    "            ensemble_search(\n",
    "                cbir_sift.retrieve(image, k=100),\n",
    "                cbir_color.retrieve(image, k=100),\n",
    "                weights=[1.0, 0.8],\n",
    "                datalength=len(dataset),\n",
    "                k = 10\n",
    "            )\n",
    "        )\n",
    "    ground_truth.extend(labels)\n",
    "avg_retrieval_time = round((time() - start) / len(dataset), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m predicted \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m r:\n\u001b[0;32m---> 11\u001b[0m     predicted\u001b[38;5;241m.\u001b[39mappend(\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m)\n\u001b[1;32m     12\u001b[0m class_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtake(dataset\u001b[38;5;241m.\u001b[39mtargets, predicted, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     13\u001b[0m ap1\u001b[38;5;241m.\u001b[39mappend(average_precision(class_preds\u001b[38;5;241m.\u001b[39mtolist(), [g\u001b[38;5;241m.\u001b[39mtolist()], \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "ap1 = []\n",
    "hit1 = []\n",
    "ap5 = []\n",
    "hit5 = []\n",
    "ap10 = []\n",
    "hit10 = []\n",
    "for r, g in zip(rs, ground_truth):\n",
    "    predicted = []\n",
    "    for i in r:\n",
    "        predicted.append(i.index)\n",
    "    class_preds = np.take(dataset.targets, predicted, axis=0)\n",
    "    ap1.append(average_precision(class_preds.tolist(), [g.tolist()], 1))\n",
    "    hit1.append(hit_rate(class_preds.tolist(), [g.tolist()], 1))\n",
    "    ap5.append(average_precision(class_preds.tolist(), [g.tolist()], 5))\n",
    "    hit5.append(hit_rate(class_preds.tolist(), [g.tolist()], 5))\n",
    "    ap10.append(average_precision(class_preds.tolist(), [g.tolist()], 10))\n",
    "    hit10.append(hit_rate(class_preds.tolist(), [g.tolist()], 10))\n",
    "\n",
    "map1 = round(np.mean(ap1), 6)\n",
    "avg_hit1 = round(np.mean(hit1), 6)\n",
    "map5 = round(np.mean(ap5), 6)\n",
    "avg_hit5 = round(np.mean(hit5), 6)\n",
    "map10 = round(np.mean(ap10), 6)\n",
    "avg_hit10 = round(np.mean(hit10), 6)\n",
    "\n",
    "print(\n",
    "            \"map@1: \", map1,\n",
    "            \"map@5: \", map5,\n",
    "            \"map@10: \", map10,\n",
    "            \"hit_rate@1: \", avg_hit1,\n",
    "            \"hit_rate@5: \", avg_hit5,\n",
    "            \"hit_rate@10: \", avg_hit10,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"out/histogram_knn_eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.max(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvbasic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
