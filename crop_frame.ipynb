{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "def crop_cell(img_path):\n",
    "    # Load the uploaded image\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    #########################\n",
    "    ##### Preprocessing #####\n",
    "    #########################\n",
    "    ############## Rotate the image to correct the orientation ################\n",
    "    ###### APPLY FILTER ON THE IMAGE TO ERASE THE TEXT AND NOISE\n",
    "    ## Convert image to grayscale image \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ## Apply Gaussian Blur for smoothing\n",
    "    gray = cv2.GaussianBlur(gray, (11, 11), 8) \n",
    "    ## Increase the brightness by 50\n",
    "    gray = cv2.convertScaleAbs(gray, alpha=1, beta=50)\n",
    "    ## Apply CLAHE to enhance constrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    gray = clahe.apply(gray)\n",
    "    ###### DETECT EDGES AND LINES TO DEFINE DOMINANT ORIENTATION\n",
    "    edges = cv2.Canny(gray, 178, 200, apertureSize=3)\n",
    "    # Use Hough Line Transformation to detect lines in the image\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)\n",
    "    # Calculate the angles of the detected lines\n",
    "    angles = []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            angle = np.degrees(theta)\n",
    "            if -10 < angle < 10:  # We filter out near-vertical lines to find the dominant orientation\n",
    "                angles.append(angle)  # Subtract 90 to normalize angle close to zero\n",
    "            if 170 < angle < 190:\n",
    "                angles.append(angle - 180)  # Subtract 90 to normalize angle close to zero\n",
    "                \n",
    "    # Compute the average angle of the lines\n",
    "    if len(angles) > 0:\n",
    "        avg_angle = np.mean(angles)\n",
    "    else:\n",
    "        avg_angle = 0  # No rotation needed if no dominant angle found\n",
    "    print(avg_angle)\n",
    "    # Rotate the image to correct the orientation\n",
    "    (h, w) = gray.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, avg_angle, 1.0)\n",
    "    rotated_image_raw = cv2.warpAffine(img, rotation_matrix, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "    # Create a figure with two subplots\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title(\"Raw Image\")\n",
    "    ax[0].axis('off')\n",
    "    ax[1].imshow(rotated_image_raw)\n",
    "    ax[1].set_title(\"Rotated Image\")\n",
    "    ax[1].axis('off')\n",
    "    ax[2].imshow(edges)\n",
    "    ax[2].set_title(\"Image edge detection\")\n",
    "    ax[2].axis('off')\n",
    "    \n",
    "    ######### PREPROCESS THE ROTATED IMAGE TO DETECT CELL ###########\n",
    "    ## Convert image to grayscale image \n",
    "    gray = cv2.cvtColor(rotated_image_raw, cv2.COLOR_BGR2GRAY)\n",
    "    ## Apply Gaussian Blur for smoothing\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 4) \n",
    "    # Define the gamma value\n",
    "    gamma = 2.2\n",
    "\n",
    "    # Apply gamma correction\n",
    "    img_gamma = np.power(gray / 255.0, gamma) * 255.0\n",
    "    gray = img_gamma.astype(np.uint8)\n",
    "    ## Increase the brightness by 50\n",
    "    gray = cv2.convertScaleAbs(gray, alpha=1, beta=50)\n",
    "    ## Apply CLAHE to enhance constrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    rotated_image = clahe.apply(gray)\n",
    "    \n",
    "    ##############################\n",
    "    ####### Mainprocessing #######\n",
    "    ##############################\n",
    "    ############## HIGHLIGHT THE VERTICAL AND HORIZONTAL LINES ################\n",
    "    img_bin = cv2.threshold(rotated_image, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (1, 29))\n",
    "    vertical_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel, iterations=3)\n",
    "    \n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (35, 1))\n",
    "    horizontal_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel, iterations=3)\n",
    "\n",
    "    # Combine the horizontal and vertical lines\n",
    "    cleaned = cv2.bitwise_or(vertical_lines, horizontal_lines)\n",
    "    edges = cv2.Canny(rotated_image * cleaned, 50, 200, apertureSize=3)\n",
    "    \n",
    "    # Show images\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(cleaned)\n",
    "    ax[0].set_title(\"Cleaned Image\")\n",
    "    ax[0].axis('off')\n",
    "    ax[1].imshow(edges)\n",
    "    ax[1].set_title(\"Edge detection\")\n",
    "    ax[1].axis('off')\n",
    "    \n",
    "    ##############################\n",
    "    ####### Postprocessing #######\n",
    "    ##############################\n",
    "    ############ DETECT CONTOURS AND FILTER OUT NOISE ############\n",
    "    # Detect contours on the morphed/dilated image\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Filter the contours based on size (ignoring small ones, which are likely noise)\n",
    "    filtered_contours = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        # Filter by size: assuming cells are large enough, we skip small areas\n",
    "        if w > 300 and h > 40 and h < 70 and w < 500:\n",
    "            filtered_contours.append(contour)\n",
    "    # Sort contours from top-to-bottom, left-to-right\n",
    "    def sort_contours(cnts):\n",
    "        bounding_boxes = [cv2.boundingRect(c) for c in cnts]\n",
    "        # Sort by row first (y), then by column (x)\n",
    "        (cnts, bounding_boxes) = zip(*sorted(zip(cnts, bounding_boxes), key=lambda b: (b[1][1], b[1][0])))\n",
    "        return cnts\n",
    "    sorted_contours = sort_contours(filtered_contours)\n",
    "    \n",
    "    print(f\"Number of cells : {len(sorted_contours)}\")\n",
    "    fig, ax = plt.subplots(math.ceil(len(sorted_contours) / 4), 4, figsize=(8, 6))\n",
    "    for a in ax.ravel():\n",
    "        a.axis('off')\n",
    "    print(ax.shape)\n",
    "    # Draw the rectangles around the cells and save them\n",
    "    for i, contour in enumerate(sorted_contours):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        cell = rotated_image_raw[y:y+h, x:x+w]\n",
    "        # Save each cell imAage\n",
    "        # cv2.imwrite(f'out/cell_{i}.png', cell)\n",
    "        ax[i//4][i%4].imshow(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_cell(\"data/prj1-4/009_0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_cell(\"data/prj1-4/001_0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_cell(\"data/prj1-4/011_0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_cell(\"data/prj1-4/012_0.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvbasic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
